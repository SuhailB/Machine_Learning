{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ad hoc mnist instances\n",
    "#from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "data = pd.read_csv('train.csv').values\n",
    "X = data[:,1:]\n",
    "Y = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(X, Y, folds, normalize):\n",
    "    \n",
    "    if(normalize==True): X = X/X.max()\n",
    "    \n",
    "    kf = KFold(n_splits=folds)\n",
    "    kf.get_n_splits(X)\n",
    "    \n",
    "    print(kf)  \n",
    "    train_data = []\n",
    "    test_data = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        train_data.append((X_train,Y_train))\n",
    "        test_data.append((X_test, Y_test))\n",
    "        \n",
    "    return train_data, test_data\n",
    "\n",
    "def getTrainingData(X, Y, train_ratio, normalize=True):\n",
    "    \n",
    "    TRAINING_SIZE = (int)(len(data)*train_ratio)\n",
    "    \n",
    "    if(normalize==True): X = X/X.max()\n",
    "    \n",
    "    X_train = X[0:TRAINING_SIZE,:]\n",
    "    Y_train = Y[0:TRAINING_SIZE]\n",
    "   \n",
    "    return X_train, Y_train\n",
    "\n",
    "def getTestingData(X, Y, train_ratio, test_size, test_remaining=False, normalize=True):\n",
    "    \n",
    "    TRAINING_SIZE = (int)(len(data)*train_ratio)\n",
    "    \n",
    "    if(normalize==True): X = X/X.max()\n",
    "    \n",
    "    if test_remaining==True:\n",
    "        X_test = X[TRAINING_SIZE:,:]\n",
    "        Y_test = Y[TRAINING_SIZE:]\n",
    "    else:\n",
    "        X_test = X[TRAINING_SIZE:TRAINING_SIZE+test_size,:]\n",
    "        Y_test = Y[TRAINING_SIZE:TRAINING_SIZE+test_size]\n",
    "    \n",
    "    return X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "KFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "set_names = [\"Non-normalized Data\", \"Normalized Data\"]\n",
    "rawTrainSets, rawTestSets = getData(X, Y, 5, False)\n",
    "normTrainSets, normTestSets = getData(X, Y, 5, True)\n",
    "train_sets = [rawTrainSets, normTrainSets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'n_estimators': 1       , 'criterion':'gini', 'bootstrap': False},\n",
    "          {'n_estimators': 1, 'criterion':'gini',     'bootstrap': True},\n",
    "          {'n_estimators': 1, 'criterion':'entropy', 'bootstrap': False },\n",
    "          {'n_estimators': 1, 'criterion':'entropy', 'bootstrap': True },\n",
    "          {'n_estimators': 10, 'criterion':'gini', 'bootstrap': False },\n",
    "          {'n_estimators': 10, 'criterion':'gini', 'bootstrap': True },\n",
    "          {'n_estimators': 10, 'criterion':'entropy', 'bootstrap': False },\n",
    "          {'n_estimators': 10, 'criterion':'entropy', 'bootstrap': True },\n",
    "          {'n_estimators': 100, 'criterion':'gini', 'bootstrap': False },\n",
    "          {'n_estimators': 100, 'criterion':'gini',     'bootstrap': True },\n",
    "          {'n_estimators': 100, 'criterion':'entropy', 'bootstrap': False },\n",
    "          {'n_estimators': 100, 'criterion':'entropy',  'bootstrap': True }]\n",
    "          \n",
    "plot_args = [{'c': 'red', 'linestyle': '-'},\n",
    "             {'c': 'red', 'linestyle': '-'},\n",
    "             {'c': 'red', 'linestyle': '-'},\n",
    "             {'c': 'green', 'linestyle': '--'},\n",
    "             {'c': 'green', 'linestyle': '--'},\n",
    "             {'c': 'green', 'linestyle': '--'},\n",
    "             {'c': 'blue', 'linestyle': '-'},\n",
    "             {'c': 'blue', 'linestyle': '-'},\n",
    "             {'c': 'blue', 'linestyle': '-'},\n",
    "             {'c': 'yellow', 'linestyle': '--'},\n",
    "             {'c': 'yellow', 'linestyle': '--'},\n",
    "             {'c': 'yellow', 'linestyle': '--'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models using Non-normalized Data \n",
      "Training using:  {'n_estimators': 1, 'criterion': 'gini', 'bootstrap': False}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 1, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 10, 'criterion': 'gini', 'bootstrap': False}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 10, 'criterion': 'gini', 'bootstrap': True}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 10, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 10, 'criterion': 'entropy', 'bootstrap': True}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 100, 'criterion': 'gini', 'bootstrap': False}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 100, 'criterion': 'gini', 'bootstrap': True}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 100, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 100, 'criterion': 'entropy', 'bootstrap': True}\n",
      "Done training!\n",
      "Training models using Normalized Data \n",
      "Training using:  {'n_estimators': 1, 'criterion': 'gini', 'bootstrap': False}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 1, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 10, 'criterion': 'gini', 'bootstrap': False}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 10, 'criterion': 'gini', 'bootstrap': True}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 10, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 10, 'criterion': 'entropy', 'bootstrap': True}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 100, 'criterion': 'gini', 'bootstrap': False}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 100, 'criterion': 'gini', 'bootstrap': True}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 100, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Done training!\n",
      "Training using:  {'n_estimators': 100, 'criterion': 'entropy', 'bootstrap': True}\n",
      "Done training!\n",
      "Done all training!\n"
     ]
    }
   ],
   "source": [
    "rfs = []\n",
    "for train_set, set_name in zip(train_sets, set_names):\n",
    "    X_train, y_train = train_set[4]\n",
    "    print(\"Training models using %s \" % set_name)\n",
    "    for param in params:\n",
    "        print(\"Training using: \", param)\n",
    "        rf = RandomForestClassifier(**param, n_jobs = -1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        rfs.append(rf)\n",
    "        print(\"Done training!\")\n",
    "print(\"Done all training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing models using Non-normalized Data \n",
      "{'n_estimators': 1, 'criterion': 'gini', 'bootstrap': False}           \t 0.8166666666666667\n",
      "{'n_estimators': 1, 'criterion': 'gini', 'bootstrap': True}            \t 0.7858333333333334\n",
      "{'n_estimators': 1, 'criterion': 'entropy', 'bootstrap': False}        \t 0.8167857142857143\n",
      "{'n_estimators': 1, 'criterion': 'entropy', 'bootstrap': True}         \t 0.800952380952381\n",
      "{'n_estimators': 10, 'criterion': 'gini', 'bootstrap': False}          \t 0.9519047619047619\n",
      "{'n_estimators': 10, 'criterion': 'gini', 'bootstrap': True}           \t 0.9367857142857143\n",
      "{'n_estimators': 10, 'criterion': 'entropy', 'bootstrap': False}       \t 0.9503571428571429\n",
      "{'n_estimators': 10, 'criterion': 'entropy', 'bootstrap': True}        \t 0.9407142857142857\n",
      "{'n_estimators': 100, 'criterion': 'gini', 'bootstrap': False}         \t 0.9689285714285715\n",
      "{'n_estimators': 100, 'criterion': 'gini', 'bootstrap': True}          \t 0.9651190476190477\n",
      "{'n_estimators': 100, 'criterion': 'entropy', 'bootstrap': False}      \t 0.9692857142857143\n",
      "{'n_estimators': 100, 'criterion': 'entropy', 'bootstrap': True}       \t 0.9644047619047619\n",
      "Testing models using Normalized Data \n",
      "{'n_estimators': 1, 'criterion': 'gini', 'bootstrap': False}           \t 0.8177380952380953\n",
      "{'n_estimators': 1, 'criterion': 'gini', 'bootstrap': True}            \t 0.7852380952380953\n",
      "{'n_estimators': 1, 'criterion': 'entropy', 'bootstrap': False}        \t 0.8271428571428572\n",
      "{'n_estimators': 1, 'criterion': 'entropy', 'bootstrap': True}         \t 0.8108333333333333\n",
      "{'n_estimators': 10, 'criterion': 'gini', 'bootstrap': False}          \t 0.9491666666666667\n",
      "{'n_estimators': 10, 'criterion': 'gini', 'bootstrap': True}           \t 0.9394047619047619\n",
      "{'n_estimators': 10, 'criterion': 'entropy', 'bootstrap': False}       \t 0.9482142857142857\n",
      "{'n_estimators': 10, 'criterion': 'entropy', 'bootstrap': True}        \t 0.9422619047619047\n",
      "{'n_estimators': 100, 'criterion': 'gini', 'bootstrap': False}         \t 0.9719047619047619\n",
      "{'n_estimators': 100, 'criterion': 'gini', 'bootstrap': True}          \t 0.9664285714285714\n",
      "{'n_estimators': 100, 'criterion': 'entropy', 'bootstrap': False}      \t 0.9697619047619047\n",
      "{'n_estimators': 100, 'criterion': 'entropy', 'bootstrap': True}       \t 0.9646428571428571\n"
     ]
    }
   ],
   "source": [
    "test_sets = [rawTestSets, normTestSets]\n",
    "i=0\n",
    "\n",
    "for test_set, set_name in zip(test_sets, set_names):\n",
    "    X_test, y_test = test_set[4]\n",
    "    print(\"Testing models using %s \" % set_name)\n",
    "    j=12*i\n",
    "    f = 12*(i+1)\n",
    "    while(j<f):\n",
    "        str1 = str(params[j%12])\n",
    "        str2 = str(rfs[j].score(X_test, y_test))\n",
    "        print(\"%-70s \\t %s\\n\" % (str1, str2), end='')\n",
    "        j += 1\n",
    "    i += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models using Non-normalized Data \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhail\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhail\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhail\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhail\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhail\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n",
      "Training models using Normalized Data \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhail\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhail\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhail\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhail\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhail\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n",
      "Done all training!\n"
     ]
    }
   ],
   "source": [
    "rfs_cv = []\n",
    "for train_set, set_name in zip(train_sets, set_names):\n",
    "    print(\"Training models using %s \" % set_name)\n",
    "    for cv_train_set in train_set:\n",
    "        X_train, y_train = cv_train_set\n",
    "        rf = RandomForestClassifier(n_jobs = -1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        rfs_cv.append(rf)\n",
    "        print(\"Done training!\")\n",
    "print(\"Done all training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing models using Non-normalized Data \n",
      "fold# 0 \t 0.9358333333333333\n",
      "fold# 1 \t 0.9382142857142857\n",
      "fold# 2 \t 0.9334523809523809\n",
      "fold# 3 \t 0.9403571428571429\n",
      "fold# 4 \t 0.9434523809523809\n",
      "Testing models using Normalized Data \n",
      "fold# 0 \t 0.9361904761904762\n",
      "fold# 1 \t 0.9341666666666667\n",
      "fold# 2 \t 0.9378571428571428\n",
      "fold# 3 \t 0.9355952380952381\n",
      "fold# 4 \t 0.9379761904761905\n"
     ]
    }
   ],
   "source": [
    "test_sets = [rawTestSets, normTestSets]\n",
    "i=0\n",
    "for test_set, set_name in zip(test_sets, set_names):\n",
    "    print(\"Testing models using %s \" % set_name)\n",
    "    j=5*i\n",
    "    f = 5*(i+1)\n",
    "    while(j<f):\n",
    "        X_test, y_test = test_set[j%5]\n",
    "        str1 = \"fold# \" + str(j%5)\n",
    "        str2 = str(rfs_cv[j].score(X_test, y_test))\n",
    "        print(\"%s \\t %s\\n\" % (str1, str2), end='')\n",
    "        j += 1\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models using Non-normalized Data \n",
      "Done training!\n",
      "Done training!\n",
      "Done training!\n",
      "Done training!\n",
      "Done training!\n",
      "Training models using Normalized Data \n",
      "Done training!\n",
      "Done training!\n",
      "Done training!\n",
      "Done training!\n",
      "Done training!\n",
      "Done all training!\n"
     ]
    }
   ],
   "source": [
    "rfs_cv_1 = []\n",
    "for train_set, set_name in zip(train_sets, set_names):\n",
    "    print(\"Training models using %s \" % set_name)\n",
    "    for cv_train_set in train_set:\n",
    "        X_train, y_train = cv_train_set\n",
    "        rf = RandomForestClassifier(**params[8], n_jobs = -1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        rfs_cv_1.append(rf)\n",
    "        print(\"Done training!\")\n",
    "print(\"Done all training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing models using Non-normalized Data \n",
      "fold# 0 \t 0.9672619047619048\n",
      "fold# 1 \t 0.9682142857142857\n",
      "fold# 2 \t 0.9676190476190476\n",
      "fold# 3 \t 0.9691666666666666\n",
      "fold# 4 \t 0.9714285714285714\n",
      "Testing models using Normalized Data \n",
      "fold# 0 \t 0.9671428571428572\n",
      "fold# 1 \t 0.9688095238095238\n",
      "fold# 2 \t 0.9657142857142857\n",
      "fold# 3 \t 0.9694047619047619\n",
      "fold# 4 \t 0.9694047619047619\n"
     ]
    }
   ],
   "source": [
    "test_sets = [rawTestSets, normTestSets]\n",
    "i=0\n",
    "for test_set, set_name in zip(test_sets, set_names):\n",
    "    print(\"Testing models using %s \" % set_name)\n",
    "    j=5*i\n",
    "    f = 5*(i+1)\n",
    "    while(j<f):\n",
    "        X_test, y_test = test_set[j%5]\n",
    "        str1 = \"fold# \" + str(j%5)\n",
    "        str2 = str(rfs_cv_1[j].score(X_test, y_test))\n",
    "        print(\"%s \\t %s\\n\" % (str1, str2), end='')\n",
    "        j += 1\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePredictions(clf, X):\n",
    "    IDs = np.arange(start=1,stop=len(X)+1)\n",
    "    IDs= IDs.reshape(len(X),1)\n",
    "    predictions = clf.predict(X)\n",
    "    predictions = predictions.reshape(len(X),1)\n",
    "    output = np.concatenate((IDs,predictions), axis=1)\n",
    "    np.savetxt(\"sample_submission.csv\", output, delimiter=\",\", fmt = '%d', header = \"ImageID,Label\", comments='')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "writePredictions(rfs_cv_1[4],test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
