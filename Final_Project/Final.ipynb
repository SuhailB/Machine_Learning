{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "KFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "data = pd.read_csv('train.csv').values\n",
    "X = data[:,1:]\n",
    "Y = data[:,0]\n",
    "\n",
    "\n",
    "def getData(X, Y, folds, normalize):\n",
    "    \n",
    "    if(normalize==True): X = X/X.max()\n",
    "    \n",
    "    kf = KFold(n_splits=folds)\n",
    "    kf.get_n_splits(X)\n",
    "    \n",
    "    print(kf)  \n",
    "    train_data = []\n",
    "    test_data = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        train_data.append((X_train,Y_train))\n",
    "        test_data.append((X_test, Y_test))\n",
    "        \n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "# def getTrainingData(X, Y, train_ratio, folds = 5,normalize=True):\n",
    "    \n",
    "#     TRAINING_SIZE = (int)(len(data)*train_ratio)\n",
    "#     training_sets = []\n",
    "#     if(normalize==True): X = X/X.max()\n",
    "#     for i in range (folds):\n",
    "#         X_train = X[TRAINING_SIZE*i:TRAINING_SIZE*(i+1),:]\n",
    "#         Y_train = Y[TRAINING_SIZE*i:TRAINING_SIZE*(i+1)]\n",
    "#         training_sets.append(zip(X_train, Y_train))\n",
    "#         print(len(X_train))\n",
    "   \n",
    "#     return training_sets\n",
    "\n",
    "# def getTestingData(X, Y, train_ratio, test_size, test_remaining=False, normalize=True):\n",
    "    \n",
    "#     TRAINING_SIZE = (int)(len(data)*train_ratio)\n",
    "    \n",
    "#     if(normalize==True): X = X/X.max()\n",
    "    \n",
    "#     if test_remaining==True:\n",
    "#         X_test = X[TRAINING_SIZE:,:]\n",
    "#         Y_test = Y[TRAINING_SIZE:]\n",
    "#     else:\n",
    "#         X_test = X[TRAINING_SIZE:TRAINING_SIZE+test_size,:]\n",
    "#         Y_test = Y[TRAINING_SIZE:TRAINING_SIZE+test_size]\n",
    "    \n",
    "#     return X_test, Y_test\n",
    "\n",
    "names = [ \"Neural Net\", \"Nearest Neighbors\", \"Random Forest\", \"Linear SVM\"]\n",
    "\n",
    "classifiers = [\n",
    "    MLPClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(max_iter = 100)\n",
    "  ]\n",
    "\n",
    "TRAINING_RATIO = 0.8\n",
    "\n",
    "set_names = [\"Non-normalized Data\", \"Normalized Data\"]\n",
    "RTrain_sets, RTest_sets = getData(X, Y, 5, False)\n",
    "NTrain_sets, NTest_sets = getData(X, Y, 5, True)\n",
    "Train_sets = [RTrain_sets, NTrain_sets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600\n",
      "8400\n"
     ]
    }
   ],
   "source": [
    "# print(len(RTrain_sets[0][1]))\n",
    "# print(len(RTest_sets[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifiers using: Non-normalized Data ...\n",
      "Training: Neural Net using different training data ...\n",
      "Training classifier using fold#: 1 ...\n",
      "Training: Neural Net ...\n",
      "Done training: Neural Net!\n",
      "Training classifier using fold#: 2 ...\n",
      "Training: Neural Net ...\n",
      "Done training: Neural Net!\n",
      "Training classifier using fold#: 3 ...\n",
      "Training: Neural Net ...\n",
      "Done training: Neural Net!\n",
      "Training classifier using fold#: 4 ...\n",
      "Training: Neural Net ...\n",
      "Done training: Neural Net!\n",
      "Training classifier using fold#: 5 ...\n",
      "Training: Neural Net ...\n",
      "Done training: Neural Net!\n",
      "Done training Neural Net using different training data!\n",
      "Training: Nearest Neighbors using different training data ...\n",
      "Training classifier using fold#: 1 ...\n",
      "Training: Nearest Neighbors ...\n",
      "Done training: Nearest Neighbors!\n",
      "Training classifier using fold#: 2 ...\n",
      "Training: Nearest Neighbors ...\n",
      "Done training: Nearest Neighbors!\n",
      "Training classifier using fold#: 3 ...\n",
      "Training: Nearest Neighbors ...\n",
      "Done training: Nearest Neighbors!\n",
      "Training classifier using fold#: 4 ...\n",
      "Training: Nearest Neighbors ...\n",
      "Done training: Nearest Neighbors!\n",
      "Training classifier using fold#: 5 ...\n",
      "Training: Nearest Neighbors ...\n",
      "Done training: Nearest Neighbors!\n",
      "Done training Nearest Neighbors using different training data!\n",
      "Training: Random Forest using different training data ...\n",
      "Training classifier using fold#: 1 ...\n",
      "Training: Random Forest ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training: Random Forest!\n",
      "Training classifier using fold#: 2 ...\n",
      "Training: Random Forest ...\n",
      "Done training: Random Forest!\n",
      "Training classifier using fold#: 3 ...\n",
      "Training: Random Forest ...\n",
      "Done training: Random Forest!\n",
      "Training classifier using fold#: 4 ...\n",
      "Training: Random Forest ...\n",
      "Done training: Random Forest!\n",
      "Training classifier using fold#: 5 ...\n",
      "Training: Random Forest ...\n",
      "Done training: Random Forest!\n",
      "Done training Random Forest using different training data!\n",
      "Training: Linear SVM using different training data ...\n",
      "Training classifier using fold#: 1 ...\n",
      "Training: Linear SVM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training: Linear SVM!\n",
      "Training classifier using fold#: 2 ...\n",
      "Training: Linear SVM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training: Linear SVM!\n",
      "Training classifier using fold#: 3 ...\n",
      "Training: Linear SVM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training: Linear SVM!\n",
      "Training classifier using fold#: 4 ...\n",
      "Training: Linear SVM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training: Linear SVM!\n",
      "Training classifier using fold#: 5 ...\n",
      "Training: Linear SVM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training: Linear SVM!\n",
      "Done training Linear SVM using different training data!\n",
      "Done training classifiers using: Non-normalized Data ...\n",
      "Training classifiers using: Normalized Data ...\n",
      "Training: Neural Net using different training data ...\n",
      "Training classifier using fold#: 1 ...\n",
      "Training: Neural Net ...\n",
      "Done training: Neural Net!\n",
      "Training classifier using fold#: 2 ...\n",
      "Training: Neural Net ...\n",
      "Done training: Neural Net!\n",
      "Training classifier using fold#: 3 ...\n",
      "Training: Neural Net ...\n",
      "Done training: Neural Net!\n",
      "Training classifier using fold#: 4 ...\n",
      "Training: Neural Net ...\n",
      "Done training: Neural Net!\n",
      "Training classifier using fold#: 5 ...\n",
      "Training: Neural Net ...\n",
      "Done training: Neural Net!\n",
      "Done training Neural Net using different training data!\n",
      "Training: Nearest Neighbors using different training data ...\n",
      "Training classifier using fold#: 1 ...\n",
      "Training: Nearest Neighbors ...\n",
      "Done training: Nearest Neighbors!\n",
      "Training classifier using fold#: 2 ...\n",
      "Training: Nearest Neighbors ...\n",
      "Done training: Nearest Neighbors!\n",
      "Training classifier using fold#: 3 ...\n",
      "Training: Nearest Neighbors ...\n",
      "Done training: Nearest Neighbors!\n",
      "Training classifier using fold#: 4 ...\n",
      "Training: Nearest Neighbors ...\n",
      "Done training: Nearest Neighbors!\n",
      "Training classifier using fold#: 5 ...\n",
      "Training: Nearest Neighbors ...\n",
      "Done training: Nearest Neighbors!\n",
      "Done training Nearest Neighbors using different training data!\n",
      "Training: Random Forest using different training data ...\n",
      "Training classifier using fold#: 1 ...\n",
      "Training: Random Forest ...\n",
      "Done training: Random Forest!\n",
      "Training classifier using fold#: 2 ...\n",
      "Training: Random Forest ...\n",
      "Done training: Random Forest!\n",
      "Training classifier using fold#: 3 ...\n",
      "Training: Random Forest ...\n",
      "Done training: Random Forest!\n",
      "Training classifier using fold#: 4 ...\n",
      "Training: Random Forest ...\n",
      "Done training: Random Forest!\n",
      "Training classifier using fold#: 5 ...\n",
      "Training: Random Forest ...\n",
      "Done training: Random Forest!\n",
      "Done training Random Forest using different training data!\n",
      "Training: Linear SVM using different training data ...\n",
      "Training classifier using fold#: 1 ...\n",
      "Training: Linear SVM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training: Linear SVM!\n",
      "Training classifier using fold#: 2 ...\n",
      "Training: Linear SVM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training: Linear SVM!\n",
      "Training classifier using fold#: 3 ...\n",
      "Training: Linear SVM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training: Linear SVM!\n",
      "Training classifier using fold#: 4 ...\n",
      "Training: Linear SVM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training: Linear SVM!\n",
      "Training classifier using fold#: 5 ...\n",
      "Training: Linear SVM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training: Linear SVM!\n",
      "Done training Linear SVM using different training data!\n",
      "Done training classifiers using: Normalized Data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1944x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#we have 5 non-normalized training data sets, and 5 normalized training data sets\n",
    "#             if(name == \"Linear SVM\" and set_name == \"Non-normalized Data\"):\n",
    "#                 print(\"model never converges\")\n",
    "#             else:\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "\n",
    "clfs = []\n",
    "\n",
    "for train_sets, set_name in zip(Train_sets, set_names):\n",
    "    print(\"Training classifiers using: %s ...\" % set_name)\n",
    "    \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        i = 1\n",
    "        print(\"Training: %s using different training data ...\" % name)\n",
    "        for train_set in train_sets:\n",
    "            print(\"Training classifier using fold#: %d ...\" % i)\n",
    "            # iterate over classifiers\n",
    "            i+=1\n",
    "            print(\"Training: %s ...\" % name)\n",
    "            X_train, Y_train = train_set\n",
    "            clf.fit(X_train, Y_train)\n",
    "            clfs.append(clf)\n",
    "            print(\"Done training: %s!\" % name)\n",
    "        print(\"Done training %s using different training data!\" % name)\n",
    "\n",
    "    \n",
    "       \n",
    "    print(\"Done training classifiers using: %s ...\" % set_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing classifiers using: Non-normalized Data ...\n",
      "Testing classifiers using fold#: 1 ...\n",
      "Testing classifiers using: Non-normalized Data ...\n",
      "Testing: Neural Net\n",
      "Classifier score: 1.000000\n",
      "Testing: Nearest Neighbors\n",
      "Classifier score: 1.000000\n",
      "Testing: Random Forest\n",
      "Classifier score: 1.000000\n",
      "Testing: Linear SVM\n",
      "Classifier score: 1.000000\n",
      "Testing classifiers using fold#: 2 ...\n",
      "Testing classifiers using: Non-normalized Data ...\n",
      "Testing: Neural Net\n",
      "Classifier score: 1.000000\n",
      "Testing: Nearest Neighbors\n",
      "Classifier score: 1.000000\n",
      "Testing: Random Forest\n",
      "Classifier score: 1.000000\n",
      "Testing: Linear SVM\n",
      "Classifier score: 1.000000\n",
      "Testing classifiers using fold#: 3 ...\n",
      "Testing classifiers using: Non-normalized Data ...\n",
      "Testing: Neural Net\n",
      "Classifier score: 1.000000\n",
      "Testing: Nearest Neighbors\n",
      "Classifier score: 1.000000\n",
      "Testing: Random Forest\n",
      "Classifier score: 1.000000\n",
      "Testing: Linear SVM\n",
      "Classifier score: 1.000000\n",
      "Testing classifiers using fold#: 4 ...\n",
      "Testing classifiers using: Non-normalized Data ...\n",
      "Testing: Neural Net\n",
      "Classifier score: 1.000000\n",
      "Testing: Nearest Neighbors\n",
      "Classifier score: 1.000000\n",
      "Testing: Random Forest\n",
      "Classifier score: 1.000000\n",
      "Testing: Linear SVM\n",
      "Classifier score: 1.000000\n",
      "Testing classifiers using fold#: 5 ...\n",
      "Testing classifiers using: Non-normalized Data ...\n",
      "Testing: Neural Net\n",
      "Classifier score: 0.970357\n",
      "Testing: Nearest Neighbors\n",
      "Classifier score: 0.970357\n",
      "Testing: Random Forest\n",
      "Classifier score: 0.970357\n",
      "Testing: Linear SVM\n",
      "Classifier score: 0.970357\n",
      "Testing classifiers using: Normalized Data ...\n",
      "Testing classifiers using fold#: 6 ...\n",
      "Testing classifiers using: Normalized Data ...\n",
      "Testing: Neural Net\n",
      "Classifier score: 1.000000\n",
      "Testing: Nearest Neighbors\n",
      "Classifier score: 1.000000\n",
      "Testing: Random Forest\n",
      "Classifier score: 1.000000\n",
      "Testing: Linear SVM\n",
      "Classifier score: 1.000000\n",
      "Testing classifiers using fold#: 7 ...\n",
      "Testing classifiers using: Normalized Data ...\n",
      "Testing: Neural Net\n",
      "Classifier score: 1.000000\n",
      "Testing: Nearest Neighbors\n",
      "Classifier score: 1.000000\n",
      "Testing: Random Forest\n",
      "Classifier score: 1.000000\n",
      "Testing: Linear SVM\n",
      "Classifier score: 1.000000\n",
      "Testing classifiers using fold#: 8 ...\n",
      "Testing classifiers using: Normalized Data ...\n",
      "Testing: Neural Net\n",
      "Classifier score: 1.000000\n",
      "Testing: Nearest Neighbors\n",
      "Classifier score: 1.000000\n",
      "Testing: Random Forest\n",
      "Classifier score: 1.000000\n",
      "Testing: Linear SVM\n",
      "Classifier score: 1.000000\n",
      "Testing classifiers using fold#: 9 ...\n",
      "Testing classifiers using: Normalized Data ...\n",
      "Testing: Neural Net\n",
      "Classifier score: 1.000000\n",
      "Testing: Nearest Neighbors\n",
      "Classifier score: 1.000000\n",
      "Testing: Random Forest\n",
      "Classifier score: 1.000000\n",
      "Testing: Linear SVM\n",
      "Classifier score: 1.000000\n",
      "Testing classifiers using fold#: 10 ...\n",
      "Testing classifiers using: Normalized Data ...\n",
      "Testing: Neural Net\n",
      "Classifier score: 0.972381\n",
      "Testing: Nearest Neighbors\n",
      "Classifier score: 0.972381\n",
      "Testing: Random Forest\n",
      "Classifier score: 0.972381\n",
      "Testing: Linear SVM\n",
      "Classifier score: 0.972381\n"
     ]
    }
   ],
   "source": [
    "Test_sets = [RTest_sets, NTest_sets]\n",
    "\n",
    "# plot_args = [{'c': 'red', 'linestyle': '-'},{'c': 'green', 'linestyle': '-'},\n",
    "#              {'c': 'blue', 'linestyle': '-'},{'c': 'yellow', 'linestyle': '-'}]\n",
    "# print(len(clfs))\n",
    "i = 1\n",
    "# fig, axes = plt.subplots(figsize=(15, 10))\n",
    "for test_sets, set_name in zip(Test_sets, set_names):\n",
    "    print(\"Testing classifiers using: %s ...\" % set_name)\n",
    "    for test_set in test_sets:\n",
    "        print(\"Testing classifiers using fold#: %d ...\" % i)\n",
    "        # iterate over classifiers\n",
    "        i+=1\n",
    "        X_test, Y_test = test_set\n",
    "        print(\"Testing classifiers using: %s ...\" % set_name)\n",
    "        for clf, name in zip(clfs, names):\n",
    "    #         if name != \"Nearest Neighbors\" and name != \"Random Forest\":\n",
    "            print(\"Testing: %s\" % name)\n",
    "            print(\"Classifier score: %f\" % clf.score(X_test, Y_test))\n",
    "#         print(\"Training set loss: %f\" % clf.loss_)\n",
    "# #             print(Y_test[0:10])\n",
    "# #             print(clf.predict(X_test[0:10]))\n",
    "# #             axes.plot(clf.loss_curve_, label=name, **plot_arg)\n",
    "#     print(\"Training set score: %f\" % mlp.score(X_test, Y_test))\n",
    "#     print(\"Training set loss: %f\" % mlp.loss_)\n",
    "#     print(mlp.loss_curve_)\n",
    "#     axes.plot(mlp.loss_curve_, label=label, **plot_arg)\n",
    "\n",
    "# fig.legend(axes.get_lines(), names, ncol = 2, loc=\"upper center\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
